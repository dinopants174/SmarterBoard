{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SmarterBoards Software Design Spring 2014 Final Project\n",
      "# An affiliate of Lazy Man Notes - Olin Project, Inc.\n",
      "# Doyung Lee and Ryan Louie \n",
      "\n",
      "# -*- coding: utf-8 -*-\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import Image\n",
      "from scipy import misc\n",
      "from skimage import io, transform, exposure\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are currently using a <b>Random Forest Classifier</b> on <b>2</b> circuit components.\n",
      "\n",
      "The paper, <a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=860185&tag=1\">Machine Recognition of Hand-Drawn Circuit Diagrams</a> , uses a <b>Nearest Neighbor Classifier</b> on <b>9</b> circuit components. \n",
      "\n",
      "This researcher, <a href=\"http://www.jacobsschool.ucsd.edu/faculty/faculty_bios/index.sfe?fmp_recid=337\">Christine Alvarado</a> , has done similar hand-drawn circuit recognition.  We should definitely follow up on her scholarly articles.\n",
      "\n",
      "<b>TO DO:</b>\n",
      "Nearest Neighbor Algorithms are our best bet given the small sample size.  Might be useful to use transform-invariant feature stuff like <a href=\"http://docs.opencv.org/modules/nonfree/doc/feature_detection.html?highlight=sift#SIFT : public Feature2D\">SIFT</a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Loading and Formatting"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Debugging Linux vs Windows Compatibility"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ryan's Linux\n",
      "\n",
      "print pd.__version__ # 0.12.0\n",
      "print np.__version__ # 1.8.1\n",
      "import skimage\n",
      "print skimage.__version__ # 0.9.3\n",
      "import scipy\n",
      "print scipy.__version__ # 0.11.0\n",
      "print scipy.__path__\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.12.0\n",
        "1.8.1\n",
        "0.9.3\n",
        "0.11.0\n",
        "['/usr/lib/python2.7/dist-packages/scipy']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OS = os.name # 'nt' if in Windows 7\n",
      "\n",
      "if OS == 'nt':\n",
      "    TRAIN_DATA_DIR = \"C:\\\\Users\\\\rlouie\\\\Documents\\\\GitHub\\\\SmarterBoard\\\\circuits\\\\data\\\\\"\n",
      "else:\n",
      "    TRAIN_DATA_DIR = \"/home/rlouie/SmarterBoard/circuits/data/\"\n",
      "    \n",
      "NUM_TRAIN = 263 # Can this be dynamically read from length of TRAIN_DATA_DIR's contents?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTrainFilenames(n=75):\n",
      "    filenames = os.listdir(TRAIN_DATA_DIR)\n",
      "    np.random.shuffle(filenames)\n",
      "    filenames = filenames[:n]\n",
      "    return filenames\n",
      "\n",
      "def isResistorFromFilename(filenames):\n",
      "    is_resistor = [fn[:3]==\"res\" for fn in filenames]\n",
      "    return is_resistor\n",
      "\n",
      "def loadImage(filename, scaler = 30):\n",
      "    image = misc.imread(filename)\n",
      "    h = []\n",
      "    for channel in range(3):\n",
      "        tmp = image.astype(np.float64)\n",
      "        h.append(exposure.histogram(tmp[:,:,channel], nbins=10)[0])\n",
      "    image = transform.resize(image, (int(scaler*1.53), int(scaler*2.56))) # small image [m,n] 153px x 256px, largeimage 1552px x 2592px\n",
      "    image = image.flatten()\n",
      "    h = np.array(h)\n",
      "    h = h.flatten()\n",
      "    return np.hstack((image, h))\n",
      "\n",
      "def loadTrain(n=75, verbose=False):\n",
      "    filenames = getTrainFilenames(n)\n",
      "    is_resistor = isResistorFromFilename(filenames)\n",
      "    I = []\n",
      "    if verbose:\n",
      "        for i in range(n):\n",
      "            fn = filenames[i]\n",
      "            print \"loading image \" + fn\n",
      "            I.append(loadImage(TRAIN_DATA_DIR + fn))\n",
      "    else:\n",
      "        for i in range(n):\n",
      "            fn = filenames[i]\n",
      "            sys.stdout.write(\".\")\n",
      "            I.append(loadImage(TRAIN_DATA_DIR + fn))      \n",
      "    return I, is_resistor\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Image Sizes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dimensions of each image follow a <b>1.53</b> by <b>2.56</b> m x n aspect ratio.  This adheres to the landscape orientation picture we took with Doyung's smartphone camera.  We adjust the number of pixels in the horizontal and vertical pixels by a scaling factor.  \n",
      "\n",
      "The challenge will be finding the right balance between having too few and too many pixels/features.  Too few, and the image is too pixelated for the classifier to pick up distinguishing features.  Too many, and the placement of the circuit component in the picture will have too drastic of an affect?\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def showcomponent(fn=\"resistor1.jpg\",scaler=100):\n",
      "    filename = (TRAIN_DATA_DIR + fn)\n",
      "    image = Image.open(filename)\n",
      "    print image\n",
      "    image = misc.fromimage(image)\n",
      "    print image\n",
      "    \n",
      "#     image = misc.imread(filename) Works with Scipy Version 0.13.3\n",
      "    print image.size\n",
      "    image = transform.resize(image, (int(scaler*1.53), int(scaler*2.56))) # small image 256px x 153px, largeimage 2592px 1552px\n",
      "    plt.imshow(image)\n",
      "    plt.title(\"Scaler={}\".format(scaler))\n",
      "    plt.xlabel('pixels')\n",
      "    plt.ylabel('pixels')\n",
      "    plt.show()\n",
      "     \n",
      "showcomponent(scaler=15)\n",
      "showcomponent(scaler=30)\n",
      "showcomponent(scaler=50)\n",
      "showcomponent(scaler=85)\n",
      "# showcomponent(fn=\"capacitor33.jpg\",scaler=40)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "shape",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-11-94dc420d9358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mshowcomponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mshowcomponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mshowcomponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-11-94dc420d9358>\u001b[0m in \u001b[0;36mshowcomponent\u001b[1;34m(fn, scaler)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     image = misc.imread(filename) Works with Scipy Version 0.13.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.53\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2.56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# small image 256px x 153px, largeimage 2592px 1552px\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scaler={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.pyc\u001b[0m in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0morig_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mrow_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_rows\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: shape"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/rlouie/SmarterBoard/circuits/data/resistor1.jpg\n",
        "(256, 153)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Let the machine learning workflow take affect!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data and Split into Training and Test Sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# --- Do Machine Learning!\n",
      "\n",
      "# Load Data\n",
      "I, is_resistor = loadTrain(NUM_TRAIN)\n",
      "I, is_resistor = (np.array(I), np.array(is_resistor))\n",
      "\n",
      "# Split into Train/Test sets\n",
      "I_train, I_test, is_resistor_train, is_resistor_test = train_test_split(I, is_resistor)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train Model\n",
      "# clf = RandomForestClassifier()\n",
      "\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "clf = KNeighborsClassifier(n_neighbors=10)\n",
      "clf.fit(I_train, is_resistor_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluate Performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate Predictions\n",
      "is_resistor_predict = clf.predict(I_test)\n",
      "print is_resistor_predict\n",
      "print is_resistor_test\n",
      "\n",
      "print \"\\naccuracy: \" + str(accuracy_score(is_resistor_test,is_resistor_predict))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analyze Model Performance, Improve Approach"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Confusion Matrix\n",
      "cm = confusion_matrix(is_resistor_test, is_resistor_predict)\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.clim(vmin=0)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}