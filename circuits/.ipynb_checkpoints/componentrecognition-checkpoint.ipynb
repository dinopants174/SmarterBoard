{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SmarterBoard Circuit Component Classification\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Abstract"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature Extraction: Exposure <b>Histograms</b> of Gabor Filtered Images along diagonal (i.e front/back-slash) gradients, <b>raw pixel values</b>."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classifiers: Nearest Neighbors, Logistic Regression, Random Forest"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Highest Average Performance: <b>88.8%</b>, LogisticRegression over 5 runs with histograms of 8 bins trained on <b> pixel values + gabor \"/\" \"\\\" histogram </b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# --- IPython Notebook Setup\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# --- Imports\n",
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import Image\n",
      "from scipy import misc\n",
      "from skimage import io, transform, exposure\n",
      "from skimage.filter import threshold_otsu, gabor_filter\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression, Perceptron\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# --- Linux vs Windows Data Directory Compatibility\n",
      "\n",
      "OS = os.name # 'nt' if in Windows 7\n",
      "\n",
      "if OS == 'nt':\n",
      "    TRAIN_DATA_DIR = os.path.join(os.path.abspath('.'),'data\\\\')\n",
      "else:\n",
      "    TRAIN_DATA_DIR = os.path.join(os.path.abspath('.'),'data/')\n",
      "    \n",
      "NUM_TRAIN = len(os.listdir(TRAIN_DATA_DIR))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature Extraction - Directional Gradient Histogram, Sobel + Gabor Filters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Preprocessing:\n",
      "    \n",
      "    @staticmethod\n",
      "    def binary_from_thresh(img):\n",
      "        \"\"\" Base function for converting to binary using a threshold \"\"\"\n",
      "        thresh = threshold_otsu(img)\n",
      "        binary = img < thresh\n",
      "        return binary\n",
      "\n",
      "    @staticmethod\n",
      "    def binary_from_laplacian(img):\n",
      "        \"\"\" Function that converts an image into binary using\n",
      "        a laplacian transform and feeding it into binary_from_thresh \"\"\"\n",
      "        laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
      "        return Preprocessing.binary_from_thresh(laplacian)\n",
      "\n",
      "    @staticmethod\n",
      "    def scale_image(img,scaler,org_dim):\n",
      "        \"\"\" resizes an image based on a certain scaler \n",
      "        args: \n",
      "            scaler: int or float. A value of 1.0 would output a image.shape = org_dim\n",
      "            org_dim: tuple. Denoting (width, height)\n",
      "        returns: ndarray. Scaled image \"\"\"\n",
      "        width, height = org_dim\n",
      "        output_size = (int(scaler*width), int(scaler*height))\n",
      "        return cv2.resize(img, output_size)\n",
      "    \n",
      "    @staticmethod\n",
      "    def standardize_shape(img):\n",
      "        \"\"\" standardizes the shape of the images to a tested shape for gabor filters \"\"\"\n",
      "        return Preprocessing.scale_image(img, scaler=.25, org_dim=(256,153))\n",
      "    \n",
      "    @staticmethod\n",
      "    def angle_pass_filter(img, frequency, theta):\n",
      "        \"\"\" returns the magnitude of a gabor filter response for a certain angle \"\"\"\n",
      "        real, imag = gabor_filter(img, frequency, theta)\n",
      "        mag = np.sqrt(np.square(real) + np.square(imag))\n",
      "        return mag\n",
      "    \n",
      "    @staticmethod\n",
      "    def frontslash_filter(img,denom=5.0,freq=0.4):\n",
      "        \"\"\" intensifies edges that look like a frontslash '/' \"\"\"\n",
      "        theta = np.pi*(1.0/denom)\n",
      "        return Preprocessing.angle_pass_filter(img,freq,theta)\n",
      "    \n",
      "    @staticmethod\n",
      "    def backslash_filter(img,denom=5.0,freq=0.4):\n",
      "        \"\"\" intensifies edges that look like a backslash '\\' \"\"\"\n",
      "        theta = np.pi*(1.0 - 1.0/denom)\n",
      "        return Preprocessing.angle_pass_filter(img,freq,theta)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-40-d75d182d9f0f>, line 5)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-d75d182d9f0f>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \"\"\" Base function for converting to binary using a threshold \"\"\"\u001b[0m\n\u001b[1;37m                                                                   ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FeatureExtraction:\n",
      "    \n",
      "    @staticmethod\n",
      "    def mean_exposure_hist(nbins, *images):\n",
      "        \"\"\" calculates mean histogram of many exposure histograms\n",
      "        args:\n",
      "            nbins: number of bins\n",
      "            *args: must be images (ndarrays) i.e r1, r2\n",
      "        returns:\n",
      "            histogram capturing pixel intensities \"\"\"\n",
      "        hists = []\n",
      "        for img in images:\n",
      "            hist, _ = exposure.histogram(img,nbins)\n",
      "            hists.append(hist)\n",
      "        return np.sum(hists, axis=0) / len(images)\n",
      "    \n",
      "    @staticmethod\n",
      "    def mean_exposure_hist_from_gabor(img,nbins):\n",
      "        frontslash = Preprocessing.frontslash_filter(img)\n",
      "        backslash = Preprocessing.backslash_filter(img)\n",
      "        return np.array(FeatureExtraction.mean_exposure_hist(nbins,frontslash,backslash))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Loading and Formatting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTrainFilenames(n):\n",
      "    filenames = os.listdir(TRAIN_DATA_DIR)\n",
      "    np.random.shuffle(filenames)\n",
      "    filenames = filenames[:n]\n",
      "    return filenames\n",
      "\n",
      "def isResistorFromFilename(filenames):\n",
      "    is_resistor = [fn[0]==\"r\" for fn in filenames]\n",
      "    return is_resistor\n",
      "\n",
      "def loadImage(filename, nbins):\n",
      "    image = cv2.imread(filename, cv2.CV_LOAD_IMAGE_GRAYSCALE) \n",
      "    image = Preprocessing.standardize_shape(image)\n",
      "    h = FeatureExtraction.mean_exposure_hist_from_gabor(image,nbins)\n",
      "    image = image.flatten()\n",
      "    return np.hstack((image, h)) # h takes up the last nbins rows of the feature vector\n",
      "\n",
      "def loadTrain(n, nbins, verbose=False):\n",
      "    filenames = getTrainFilenames(n)\n",
      "    is_resistor = isResistorFromFilename(filenames)\n",
      "    I = []\n",
      "    if verbose:\n",
      "        for i in range(n):\n",
      "            fn = filenames[i]\n",
      "            print os.sys.stdout.write('.')\n",
      "            I.append(loadImage(TRAIN_DATA_DIR + fn, nbins))\n",
      "    else:\n",
      "        for i in range(n):\n",
      "            fn = filenames[i]\n",
      "            I.append(loadImage(TRAIN_DATA_DIR + fn, nbins))      \n",
      "    return I, is_resistor\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Component Classification System"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def component_clf_sys(nbins, clf):\n",
      "    \"\"\" returns an accuracy score for X (pixels + hist)\n",
      "    \n",
      "    nbins: number of bins for exposure histogram of the gabor filtered images\n",
      "    clf: an instantiated classifier object\n",
      "    \"\"\"\n",
      "#     print \"\\nLoading Images and Extracting Features...\"\n",
      "    X, y = loadTrain(NUM_TRAIN, nbins)\n",
      "    X, y = (np.array(X), np.array(y))\n",
      "\n",
      "#     print \"\\nSplitting into Training and Test Sets...\"\n",
      "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.66)\n",
      "    \n",
      "#     print \"\\nTraining Classifier...\"\n",
      "    clf.fit(X_train, y_train)\n",
      "    \n",
      "    # Evaluate Predictions\n",
      "    y_pred = clf.predict(X_test)\n",
      "\n",
      "    \n",
      "    accuracy = accuracy_score(y_test,y_pred)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Average performance for nruns of the component classification system"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.cs.toronto.edu/~psala/ML/ML-Project.pdf\"> Component Recognition Paper </a> , if we want to imporve our accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_perf_component_clf_sys(nruns, nbins, clf):\n",
      "    \"\"\" Caculates average accuracy performance from nruns of the classifier system\n",
      "    \n",
      "    nruns: number of runs\n",
      "    nbins: number of bins for the exposure histogram\n",
      "    clf: instantiated classifier object\n",
      "    \"\"\"\n",
      "    perf = []\n",
      "    for i in xrange(nruns):\n",
      "        accuracy = component_clf_sys(nbins, clf) \n",
      "        perf.append(accuracy)\n",
      "    return np.mean(perf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "KNeighborsClassifier performance over 5 runs for a 8 bin histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compareClassifiers(clfs):\n",
      "    \"\"\" Caculates average performance of the component classification system for given ML Classifiers \"\"\"\n",
      "    for clf in clfs:\n",
      "        avg_perf = avg_perf_component_clf_sys(5, 8, clf)\n",
      "        print \"\\nAverage performance of {} when trained on pixels + histogram: \".format(clf.__str__()) + str(avg_perf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifiers = [\n",
      "    LogisticRegression(),\n",
      "    SVC(kernel='linear')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compareClassifiers(classifiers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance of KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=3, p=2, weights=uniform) when trained on pixels + histogram: 0.707070707071\n",
        "\n",
        "Average performance of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty=l2, random_state=None, tol=0.0001) when trained on pixels + histogram: 0.872727272727"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Average performance of Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False) when trained on pixels + histogram: 0.624242424242"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Average performance of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel=rbf, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False) when trained on pixels + histogram: 0.513131313131"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Average performance of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel=linear, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False) when trained on pixels + histogram: 0.866666666667"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compareClassifier(LogisticRegression)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance of LogisticRegression when trained on pixels + histogram: 0.878787878788\n",
        "\n",
        "Average performance of LogisticRegression when trained on histogram alone: 0.818181818182\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compareClassifier(GaussianNB)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance of GaussianNB when trained on pixels + histogram: 0.733333333333\n",
        "\n",
        "Average performance of GaussianNB when trained on histogram alone: 0.844444444444\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compareKNN():\n",
      "    avg_perf_X, avg_perf_h = avg_perf_component_clf_sys(5, 8, KNeighborsClassifier)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=KNN) when trained on pixels + histogram: \" + str(avg_perf_X)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=KNN) when trained on histogram alone: \" + str(avg_perf_h)\n",
      "\n",
      "compareKNN()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance (nruns=5,nbins=8,clf=KNN) when trained on pixels + histogram: 0.731313131313\n",
        "\n",
        "Average performance (nruns=5,nbins=8,clf=KNN) when trained on histogram alone: 0.824242424242\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "LogisticRegressions performance over 5 runs for a 8 bin histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compareLogisticRegression():\n",
      "    avg_perf_X, avg_perf_h = avg_perf_component_clf_sys(5, 8, LogisticRegression)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=GMM) when trained on pixels + histogram: \" + str(avg_perf_X)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=GMM) when trained on histogram alone: \" + str(avg_perf_h)\n",
      "    \n",
      "compareLogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance (nruns=5,nbins=8,clf=GMM) when trained on pixels + histogram: 0.862626262626\n",
        "\n",
        "Average performance (nruns=5,nbins=8,clf=GMM) when trained on histogram alone: 0.838383838384\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "RandomForestClassifier performance over 5 runs for a 8 bin histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compareRF():\n",
      "    avg_perf_X, avg_perf_h = avg_perf_component_clf_sys(5, 8, RandomForestClassifier)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=GMM) when trained on pixels + histogram: \" + str(avg_perf_X)\n",
      "    print \"\\nAverage performance (nruns=5,nbins=8,clf=GMM) when trained on histogram alone: \" + str(avg_perf_h)\n",
      "    \n",
      "compareRF()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average performance (nruns=5,nbins=8,clf=GMM) when trained on pixels + histogram: 0.80202020202\n",
        "\n",
        "Average performance (nruns=5,nbins=8,clf=GMM) when trained on histogram alone: 0.80404040404\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Confusion Matrix (TODO)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# assert(len(y_predh) == len(y_test))\n",
      "\n",
      "# for i in range(len(y_predh)):\n",
      "#     if y_predh[i] != y_test[i]:\n",
      "#         misclassified_image = I_test[i]\n",
      "#         scaler=.25\n",
      "#         org_dim=(256,153)\n",
      "#         width, height = org_dim\n",
      "#         landscape_shape = (int(height*scaler),int(width*scaler))\n",
      "#         misclassified_image = misclassified_image.reshape(landscape_shape)\n",
      "        \n",
      "#         plt.imshow(misclassified_image,cmap='grey')\n",
      "#         plt.title(\"Misclassified Image, i = {}\".format(i))\n",
      "#         plt.xlabel('pixels')\n",
      "#         plt.ylabel('pixels')\n",
      "#         plt.show()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "total size of new array must be unchanged",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-97-51ea76294759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morg_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlandscape_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmisclassified_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmisclassified_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlandscape_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmisclassified_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'grey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: total size of new array must be unchanged"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}